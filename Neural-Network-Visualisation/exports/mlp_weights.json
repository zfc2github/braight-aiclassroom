{
  "version": 2,
  "dtype": "float16",
  "weights": {
    "storage": "per_snapshot_files",
    "format": "layer_array_v1",
    "precision": "float16"
  },
  "network": {
    "architecture": [
      784,
      128,
      64,
      10
    ],
    "layers": [
      {
        "layer_index": 0,
        "type": "dense",
        "name": "dense_0",
        "activation": "relu",
        "weight_shape": [
          128,
          784
        ],
        "bias_shape": [
          128
        ]
      },
      {
        "layer_index": 1,
        "type": "dense",
        "name": "dense_1",
        "activation": "relu",
        "weight_shape": [
          64,
          128
        ],
        "bias_shape": [
          64
        ]
      },
      {
        "layer_index": 2,
        "type": "dense",
        "name": "dense_2",
        "activation": "linear",
        "weight_shape": [
          10,
          64
        ],
        "bias_shape": [
          10
        ]
      }
    ],
    "input_dim": 784,
    "output_dim": 10,
    "normalization": {
      "mean": 0.1307,
      "std": 0.3081
    }
  },
  "timeline": [
    {
      "id": "initial",
      "order": 0,
      "label": "Initial weights",
      "kind": "initial",
      "target_images": 0,
      "images_seen": 0,
      "batches_seen": 0,
      "dataset_passes": 0.0,
      "description": "0 images processed (random initialisation)",
      "metrics": {
        "test_accuracy": 0.1375
      },
      "weights": {
        "path": "mlp_weights/000_initial.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      }
    },
    {
      "id": "approx_50",
      "order": 1,
      "label": "\u224850 images",
      "kind": "approx",
      "target_images": 50,
      "images_seen": 128,
      "batches_seen": 1,
      "dataset_passes": 0.0021333333333333334,
      "description": "128 images processed \u2022 1 batches \u2022 0.00\u00d7 dataset",
      "metrics": {
        "test_accuracy": 0.252,
        "avg_training_loss": 2.318258285522461
      },
      "weights": {
        "path": "mlp_weights/001_approx-50.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      }
    },
    {
      "id": "approx_120",
      "order": 2,
      "label": "\u2248120 images",
      "kind": "approx",
      "target_images": 120,
      "images_seen": 128,
      "batches_seen": 1,
      "dataset_passes": 0.0021333333333333334,
      "description": "128 images processed \u2022 1 batches \u2022 0.00\u00d7 dataset",
      "metrics": {
        "test_accuracy": 0.252,
        "avg_training_loss": 2.318258285522461
      },
      "weights": {
        "path": "mlp_weights/002_approx-120.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      }
    },
    {
      "id": "approx_250",
      "order": 3,
      "label": "\u2248250 images",
      "kind": "approx",
      "target_images": 250,
      "images_seen": 256,
      "batches_seen": 2,
      "dataset_passes": 0.004266666666666667,
      "description": "256 images processed \u2022 2 batches \u2022 0.00\u00d7 dataset",
      "metrics": {
        "test_accuracy": 0.3617,
        "avg_training_loss": 2.273592472076416
      },
      "weights": {
        "path": "mlp_weights/003_approx-250.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      }
    },
    {
      "id": "approx_500",
      "order": 4,
      "label": "\u2248500 images",
      "kind": "approx",
      "target_images": 500,
      "images_seen": 512,
      "batches_seen": 4,
      "dataset_passes": 0.008533333333333334,
      "description": "512 images processed \u2022 4 batches \u2022 0.01\u00d7 dataset",
      "metrics": {
        "test_accuracy": 0.4532,
        "avg_training_loss": 2.2220916748046875
      },
      "weights": {
        "path": "mlp_weights/004_approx-500.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      }
    },
    {
      "id": "approx_1k",
      "order": 5,
      "label": "\u22481k images",
      "kind": "approx",
      "target_images": 1000,
      "images_seen": 1024,
      "batches_seen": 8,
      "dataset_passes": 0.017066666666666667,
      "description": "1,024 images processed \u2022 8 batches \u2022 0.02\u00d7 dataset",
      "metrics": {
        "test_accuracy": 0.5534,
        "avg_training_loss": 2.0986886620521545
      },
      "weights": {
        "path": "mlp_weights/005_approx-1k.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      }
    },
    {
      "id": "approx_2k",
      "order": 6,
      "label": "\u22482k images",
      "kind": "approx",
      "target_images": 2000,
      "images_seen": 2048,
      "batches_seen": 16,
      "dataset_passes": 0.034133333333333335,
      "description": "2,048 images processed \u2022 16 batches \u2022 0.03\u00d7 dataset",
      "metrics": {
        "test_accuracy": 0.7241,
        "avg_training_loss": 1.7861761301755905
      },
      "weights": {
        "path": "mlp_weights/006_approx-2k.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      }
    },
    {
      "id": "approx_3_5k",
      "order": 7,
      "label": "\u22483.5k images",
      "kind": "approx",
      "target_images": 3500,
      "images_seen": 3584,
      "batches_seen": 28,
      "dataset_passes": 0.05973333333333333,
      "description": "3,584 images processed \u2022 28 batches \u2022 0.06\u00d7 dataset",
      "metrics": {
        "test_accuracy": 0.8315,
        "avg_training_loss": 1.3815991559198924
      },
      "weights": {
        "path": "mlp_weights/007_approx-3-5k.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      }
    },
    {
      "id": "approx_5_8k",
      "order": 8,
      "label": "\u22485.8k images",
      "kind": "approx",
      "target_images": 5800,
      "images_seen": 5888,
      "batches_seen": 46,
      "dataset_passes": 0.09813333333333334,
      "description": "5,888 images processed \u2022 46 batches \u2022 0.10\u00d7 dataset",
      "metrics": {
        "test_accuracy": 0.8793,
        "avg_training_loss": 1.042623273704363
      },
      "weights": {
        "path": "mlp_weights/008_approx-5-8k.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      }
    },
    {
      "id": "approx_8_7k",
      "order": 9,
      "label": "\u22488.7k images",
      "kind": "approx",
      "target_images": 8700,
      "images_seen": 8704,
      "batches_seen": 68,
      "dataset_passes": 0.14506666666666668,
      "description": "8,704 images processed \u2022 68 batches \u2022 0.15\u00d7 dataset",
      "metrics": {
        "test_accuracy": 0.8797,
        "avg_training_loss": 0.8291185336077914
      },
      "weights": {
        "path": "mlp_weights/009_approx-8-7k.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      }
    },
    {
      "id": "approx_13k",
      "order": 10,
      "label": "\u224813k images",
      "kind": "approx",
      "target_images": 13000,
      "images_seen": 13056,
      "batches_seen": 102,
      "dataset_passes": 0.2176,
      "description": "13,056 images processed \u2022 102 batches \u2022 0.22\u00d7 dataset",
      "metrics": {
        "test_accuracy": 0.9132,
        "avg_training_loss": 0.6702231720966452
      },
      "weights": {
        "path": "mlp_weights/010_approx-13k.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      }
    },
    {
      "id": "approx_19_5k",
      "order": 11,
      "label": "\u224819.5k images",
      "kind": "approx",
      "target_images": 19500,
      "images_seen": 19584,
      "batches_seen": 153,
      "dataset_passes": 0.3264,
      "description": "19,584 images processed \u2022 153 batches \u2022 0.33\u00d7 dataset",
      "metrics": {
        "test_accuracy": 0.9165,
        "avg_training_loss": 0.5470870994274912
      },
      "weights": {
        "path": "mlp_weights/011_approx-19-5k.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      }
    },
    {
      "id": "approx_28_5k",
      "order": 12,
      "label": "\u224828.5k images",
      "kind": "approx",
      "target_images": 28500,
      "images_seen": 28544,
      "batches_seen": 223,
      "dataset_passes": 0.47573333333333334,
      "description": "28,544 images processed \u2022 223 batches \u2022 0.48\u00d7 dataset",
      "metrics": {
        "test_accuracy": 0.9321,
        "avg_training_loss": 0.4570673514374703
      },
      "weights": {
        "path": "mlp_weights/012_approx-28-5k.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      }
    },
    {
      "id": "approx_40k",
      "order": 13,
      "label": "\u224840k images",
      "kind": "approx",
      "target_images": 40000,
      "images_seen": 40064,
      "batches_seen": 313,
      "dataset_passes": 0.6677333333333333,
      "description": "40,064 images processed \u2022 313 batches \u2022 0.67\u00d7 dataset",
      "metrics": {
        "test_accuracy": 0.9432,
        "avg_training_loss": 0.3905749294323662
      },
      "weights": {
        "path": "mlp_weights/013_approx-40k.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      }
    },
    {
      "id": "dataset_1x",
      "order": 14,
      "label": "1\u00d7 dataset",
      "kind": "dataset_multiple",
      "target_images": 60000,
      "images_seen": 60000,
      "batches_seen": 469,
      "dataset_passes": 1.0,
      "description": "60,000 images \u2022 1\u00d7 dataset \u2022 469 batches",
      "metrics": {
        "test_accuracy": 0.9539,
        "avg_training_loss": 0.3209175285657247
      },
      "weights": {
        "path": "mlp_weights/014_dataset-1x.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      },
      "dataset_multiple": 1.0
    },
    {
      "id": "approx_80k",
      "order": 15,
      "label": "\u224880k images",
      "kind": "approx",
      "target_images": 80000,
      "images_seen": 80096,
      "batches_seen": 626,
      "dataset_passes": 1.3349333333333333,
      "description": "80,096 images processed \u2022 626 batches \u2022 1.33\u00d7 dataset",
      "metrics": {
        "test_accuracy": 0.9597,
        "avg_training_loss": 0.27560593552747537
      },
      "weights": {
        "path": "mlp_weights/015_approx-80k.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      }
    },
    {
      "id": "dataset_1_5x",
      "order": 16,
      "label": "1.5\u00d7 dataset",
      "kind": "dataset_multiple",
      "target_images": 90000,
      "images_seen": 90080,
      "batches_seen": 704,
      "dataset_passes": 1.5013333333333334,
      "description": "90,080 images \u2022 1.5\u00d7 dataset \u2022 704 batches",
      "metrics": {
        "test_accuracy": 0.9631,
        "avg_training_loss": 0.25851080862285825
      },
      "weights": {
        "path": "mlp_weights/016_dataset-1-5x.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      },
      "dataset_multiple": 1.5
    },
    {
      "id": "dataset_2x",
      "order": 17,
      "label": "2\u00d7 dataset",
      "kind": "dataset_multiple",
      "target_images": 120000,
      "images_seen": 120000,
      "batches_seen": 938,
      "dataset_passes": 2.0,
      "description": "120,000 images \u2022 2\u00d7 dataset \u2022 938 batches",
      "metrics": {
        "test_accuracy": 0.9646,
        "avg_training_loss": 0.22427394441167514
      },
      "weights": {
        "path": "mlp_weights/017_dataset-2x.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      },
      "dataset_multiple": 2.0
    },
    {
      "id": "dataset_2_5x",
      "order": 18,
      "label": "2.5\u00d7 dataset",
      "kind": "dataset_multiple",
      "target_images": 150000,
      "images_seen": 150080,
      "batches_seen": 1173,
      "dataset_passes": 2.501333333333333,
      "description": "150,080 images \u2022 2.5\u00d7 dataset \u2022 1,173 batches",
      "metrics": {
        "test_accuracy": 0.9684,
        "avg_training_loss": 0.19729697190558732
      },
      "weights": {
        "path": "mlp_weights/018_dataset-2-5x.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      },
      "dataset_multiple": 2.5
    },
    {
      "id": "dataset_3x",
      "order": 19,
      "label": "3\u00d7 dataset",
      "kind": "dataset_multiple",
      "target_images": 180000,
      "images_seen": 180000,
      "batches_seen": 1407,
      "dataset_passes": 3.0,
      "description": "180,000 images \u2022 3\u00d7 dataset \u2022 1,407 batches",
      "metrics": {
        "test_accuracy": 0.9716,
        "avg_training_loss": 0.17897553289665116
      },
      "weights": {
        "path": "mlp_weights/019_dataset-3x.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      },
      "dataset_multiple": 3.0
    },
    {
      "id": "dataset_4x",
      "order": 20,
      "label": "4\u00d7 dataset",
      "kind": "dataset_multiple",
      "target_images": 240000,
      "images_seen": 240000,
      "batches_seen": 1876,
      "dataset_passes": 4.0,
      "description": "240,000 images \u2022 4\u00d7 dataset \u2022 1,876 batches",
      "metrics": {
        "test_accuracy": 0.9754,
        "avg_training_loss": 0.15087367727557818
      },
      "weights": {
        "path": "mlp_weights/020_dataset-4x.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      },
      "dataset_multiple": 4.0
    },
    {
      "id": "dataset_5x",
      "order": 21,
      "label": "5\u00d7 dataset",
      "kind": "dataset_multiple",
      "target_images": 300000,
      "images_seen": 300000,
      "batches_seen": 2345,
      "dataset_passes": 5.0,
      "description": "300,000 images \u2022 5\u00d7 dataset \u2022 2,345 batches",
      "metrics": {
        "test_accuracy": 0.9717,
        "avg_training_loss": 0.13142688159386318
      },
      "weights": {
        "path": "mlp_weights/021_dataset-5x.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      },
      "dataset_multiple": 5.0
    },
    {
      "id": "dataset_6_5x",
      "order": 22,
      "label": "6.5\u00d7 dataset",
      "kind": "dataset_multiple",
      "target_images": 390000,
      "images_seen": 390080,
      "batches_seen": 3049,
      "dataset_passes": 6.501333333333333,
      "description": "390,080 images \u2022 6.5\u00d7 dataset \u2022 3,049 batches",
      "metrics": {
        "test_accuracy": 0.979,
        "avg_training_loss": 0.11078209049764401
      },
      "weights": {
        "path": "mlp_weights/022_dataset-6-5x.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      },
      "dataset_multiple": 6.5
    },
    {
      "id": "dataset_8_5x",
      "order": 23,
      "label": "8.5\u00d7 dataset",
      "kind": "dataset_multiple",
      "target_images": 510000,
      "images_seen": 510080,
      "batches_seen": 3987,
      "dataset_passes": 8.501333333333333,
      "description": "510,080 images \u2022 8.5\u00d7 dataset \u2022 3,987 batches",
      "metrics": {
        "test_accuracy": 0.9776,
        "avg_training_loss": 0.09172532411944823
      },
      "weights": {
        "path": "mlp_weights/023_dataset-8-5x.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      },
      "dataset_multiple": 8.5
    },
    {
      "id": "dataset_10x",
      "order": 24,
      "label": "10\u00d7 dataset",
      "kind": "dataset_multiple",
      "target_images": 600000,
      "images_seen": 600000,
      "batches_seen": 4690,
      "dataset_passes": 10.0,
      "description": "600,000 images \u2022 10\u00d7 dataset \u2022 4,690 batches",
      "metrics": {
        "test_accuracy": 0.977,
        "avg_training_loss": 0.08172680414684116
      },
      "weights": {
        "path": "mlp_weights/024_dataset-10x.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      },
      "dataset_multiple": 10.0
    },
    {
      "id": "dataset_12_5x",
      "order": 25,
      "label": "12.5\u00d7 dataset",
      "kind": "dataset_multiple",
      "target_images": 750000,
      "images_seen": 750080,
      "batches_seen": 5863,
      "dataset_passes": 12.501333333333333,
      "description": "750,080 images \u2022 12.5\u00d7 dataset \u2022 5,863 batches",
      "metrics": {
        "test_accuracy": 0.9747,
        "avg_training_loss": 0.06874381689089168
      },
      "weights": {
        "path": "mlp_weights/025_dataset-12-5x.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      },
      "dataset_multiple": 12.5
    },
    {
      "id": "dataset_15x",
      "order": 26,
      "label": "15\u00d7 dataset",
      "kind": "dataset_multiple",
      "target_images": 900000,
      "images_seen": 900000,
      "batches_seen": 7035,
      "dataset_passes": 15.0,
      "description": "900,000 images \u2022 15\u00d7 dataset \u2022 7,035 batches",
      "metrics": {
        "test_accuracy": 0.9758,
        "avg_training_loss": 0.05990715338343133
      },
      "weights": {
        "path": "mlp_weights/026_dataset-15x.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      },
      "dataset_multiple": 15.0
    },
    {
      "id": "dataset_17_5x",
      "order": 27,
      "label": "17.5\u00d7 dataset",
      "kind": "dataset_multiple",
      "target_images": 1050000,
      "images_seen": 1050080,
      "batches_seen": 8208,
      "dataset_passes": 17.501333333333335,
      "description": "1,050,080 images \u2022 17.5\u00d7 dataset \u2022 8,208 batches",
      "metrics": {
        "test_accuracy": 0.979,
        "avg_training_loss": 0.052932906627145095
      },
      "weights": {
        "path": "mlp_weights/027_dataset-17-5x.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      },
      "dataset_multiple": 17.5
    },
    {
      "id": "dataset_20x",
      "order": 28,
      "label": "20\u00d7 dataset",
      "kind": "dataset_multiple",
      "target_images": 1200000,
      "images_seen": 1200000,
      "batches_seen": 9380,
      "dataset_passes": 20.0,
      "description": "1,200,000 images \u2022 20\u00d7 dataset \u2022 9,380 batches",
      "metrics": {
        "test_accuracy": 0.9788,
        "avg_training_loss": 0.04783339347316379
      },
      "weights": {
        "path": "mlp_weights/028_dataset-20x.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      },
      "dataset_multiple": 20.0
    },
    {
      "id": "dataset_25x",
      "order": 29,
      "label": "25\u00d7 dataset",
      "kind": "dataset_multiple",
      "target_images": 1500000,
      "images_seen": 1500000,
      "batches_seen": 11725,
      "dataset_passes": 25.0,
      "description": "1,500,000 images \u2022 25\u00d7 dataset \u2022 11,725 batches",
      "metrics": {
        "test_accuracy": 0.9793,
        "avg_training_loss": 0.04011526816737574
      },
      "weights": {
        "path": "mlp_weights/029_dataset-25x.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      },
      "dataset_multiple": 25.0
    },
    {
      "id": "dataset_30x",
      "order": 30,
      "label": "30\u00d7 dataset",
      "kind": "dataset_multiple",
      "target_images": 1800000,
      "images_seen": 1800000,
      "batches_seen": 14070,
      "dataset_passes": 30.0,
      "description": "1,800,000 images \u2022 30\u00d7 dataset \u2022 14,070 batches",
      "metrics": {
        "test_accuracy": 0.9802,
        "avg_training_loss": 0.03463914606095505
      },
      "weights": {
        "path": "mlp_weights/030_dataset-30x.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      },
      "dataset_multiple": 30.0
    },
    {
      "id": "dataset_35x",
      "order": 31,
      "label": "35\u00d7 dataset",
      "kind": "dataset_multiple",
      "target_images": 2100000,
      "images_seen": 2100000,
      "batches_seen": 16415,
      "dataset_passes": 35.0,
      "description": "2,100,000 images \u2022 35\u00d7 dataset \u2022 16,415 batches",
      "metrics": {
        "test_accuracy": 0.9792,
        "avg_training_loss": 0.030765175048975562
      },
      "weights": {
        "path": "mlp_weights/031_dataset-35x.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      },
      "dataset_multiple": 35.0
    },
    {
      "id": "dataset_40x",
      "order": 32,
      "label": "40\u00d7 dataset",
      "kind": "dataset_multiple",
      "target_images": 2400000,
      "images_seen": 2400000,
      "batches_seen": 18760,
      "dataset_passes": 40.0,
      "description": "2,400,000 images \u2022 40\u00d7 dataset \u2022 18,760 batches",
      "metrics": {
        "test_accuracy": 0.9803,
        "avg_training_loss": 0.027775665313667063
      },
      "weights": {
        "path": "mlp_weights/032_dataset-40x.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      },
      "dataset_multiple": 40.0
    },
    {
      "id": "dataset_45x",
      "order": 33,
      "label": "45\u00d7 dataset",
      "kind": "dataset_multiple",
      "target_images": 2700000,
      "images_seen": 2700000,
      "batches_seen": 21105,
      "dataset_passes": 45.0,
      "description": "2,700,000 images \u2022 45\u00d7 dataset \u2022 21,105 batches",
      "metrics": {
        "test_accuracy": 0.9775,
        "avg_training_loss": 0.025380229007694655
      },
      "weights": {
        "path": "mlp_weights/033_dataset-45x.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      },
      "dataset_multiple": 45.0
    },
    {
      "id": "dataset_50x",
      "order": 34,
      "label": "50\u00d7 dataset",
      "kind": "dataset_multiple",
      "target_images": 3000000,
      "images_seen": 3000000,
      "batches_seen": 23450,
      "dataset_passes": 50.0,
      "description": "3,000,000 images \u2022 50\u00d7 dataset \u2022 23,450 batches",
      "metrics": {
        "test_accuracy": 0.9816,
        "avg_training_loss": 0.023422177559777473
      },
      "weights": {
        "path": "mlp_weights/034_dataset-50x.json",
        "dtype": "float16",
        "format": "layer_array_v1"
      },
      "dataset_multiple": 50.0
    }
  ]
}